\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Chapter 11: Introduction to Deep Learning}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}What is deep learning and why now?}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Perceptron - The first neural network}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Components of a deep learning system}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Linear layers and activation functions}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Linear Transformations (In hidden layers)}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Intermediate Activation Functions (In hidden layers)}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Output Activation Functions (In output layer)}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}Loss function}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Gradient descent}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}Forward Computation (Forward Propagation)}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.2}Backward Computation (Backward Propagation)}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.3}Gradient and its Importance}{6}{}\protected@file@percent }
\gdef \@abspage@last{6}
